{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dcc6cb4",
   "metadata": {},
   "source": [
    "# Módulo 12: Prompt Engineering\n",
    "\n",
    "Este notebook corresponde a la entrega del ejercicio entregable (actividad 2) del módulo de Prompt Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7eca9e",
   "metadata": {},
   "source": [
    "## Paso 0: toma de contacto con los datos\n",
    "\n",
    "Primero vamos a cargar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a40d9b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Contenido</th>\n",
       "      <th>Valoración</th>\n",
       "      <th>Recomendado_binario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2 marzo so bad</td>\n",
       "      <td>No recomendado</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10 febrero actualmente recomiendo juego contab...</td>\n",
       "      <td>No recomendado</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9 febrero increíblemente gracioso ver cómo cdp...</td>\n",
       "      <td>No recomendado</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>the world in this game is extremely static the...</td>\n",
       "      <td>No recomendado</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>zero replayability i finished this game in abo...</td>\n",
       "      <td>No recomendado</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          Contenido  \\\n",
       "0           0                                     2 marzo so bad   \n",
       "1           1  10 febrero actualmente recomiendo juego contab...   \n",
       "2           2  9 febrero increíblemente gracioso ver cómo cdp...   \n",
       "3           3  the world in this game is extremely static the...   \n",
       "4           4  zero replayability i finished this game in abo...   \n",
       "\n",
       "       Valoración  Recomendado_binario  \n",
       "0  No recomendado                    0  \n",
       "1  No recomendado                    0  \n",
       "2  No recomendado                    0  \n",
       "3  No recomendado                    0  \n",
       "4  No recomendado                    0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(\"videogames_reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "844487de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos por columna:\n",
      "Unnamed: 0               0\n",
      "Contenido              288\n",
      "Valoración               0\n",
      "Recomendado_binario      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores nulos por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b8d82b",
   "metadata": {},
   "source": [
    "Vamos a limpiar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c24147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limpiamos valores nulos\n",
    "df_clean = df.dropna(subset=[\"Contenido\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5dce92",
   "metadata": {},
   "source": [
    "## Paso 1: filtrar opiniones de mayor longitud (reducción del universo)\n",
    "\n",
    "El primer paso es reducir las 20k muestras en una menor cantidad para poder manejarlas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7a1ad4",
   "metadata": {},
   "source": [
    "Vamos a obtener las opiniones que tengan una longitud mayor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49bf57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['content_length'] = df_clean['Contenido'].str.len()\n",
    "df_top_100 = df_clean.nlargest(100, 'content_length').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a0b317",
   "metadata": {},
   "source": [
    "Eliminamos columnas irrelevantes y cambiamos nombre a inglés (más estándar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "953649b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>is_recomended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>suiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this was probably my first preorder i felt tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oh well admittedly its difficult for to write ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oh well admittedly its difficult for to write ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i know many will handwave away any criticisms ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  is_recomended\n",
       "0  suiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii...              1\n",
       "1  this was probably my first preorder i felt tha...              1\n",
       "2  oh well admittedly its difficult for to write ...              0\n",
       "3  oh well admittedly its difficult for to write ...              0\n",
       "4  i know many will handwave away any criticisms ...              0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_100 = df_top_100.drop(columns=[\"Unnamed: 0\", \"Valoración\", \"content_length\"], errors=\"ignore\")\n",
    "df_top_100 = df_top_100.rename(columns={\"Recomendado_binario\": \"is_recomended\", \"Contenido\": \"content\"})\n",
    "df_top_100.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360e400f",
   "metadata": {},
   "source": [
    "## Paso 2: clasificación por relevancia\n",
    "\n",
    "Como vemos, la primera de las opiniones podría considerarse como no relevante, dado que no aporta información útil.\n",
    "\n",
    "Utilizamos un modelo de generación de texto con prompting para clasificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "be293737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 338/338 [00:02<00:00, 117.07it/s, Materializing param=model.norm.weight]                              \n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "195b8d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=2) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "prompt = \"\"\"You are an elite content moderator for a gaming forum. \n",
    "Your task is to classify user reviews into RELEVANT or SPAM.\n",
    "\n",
    "### DEFINITIONS:\n",
    "- RELEVANT: Meaningful opinions about game mechanics, bugs, story, developers, or comparisons. Even if the tone is toxic or negative, if it discusses the game, it is RELEVANT.\n",
    "- SPAM: Nonsense text, character repetition (e.g., \"suiiii\"), keyboard smashing, or single-word shouts that provide no feedback.\n",
    "\n",
    "### EXAMPLES:\n",
    "\n",
    "Review: \"The physics engine in this game is broken. I fell through the floor five times in an hour. Trash devs.\"\n",
    "Result: RELEVANT\n",
    "\n",
    "Review: \"suiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\"\n",
    "Result: SPAM\n",
    "\n",
    "Review: \"This game is a shovelware imitation of a game that never existed, a total garbagefire.\"\n",
    "Result: RELEVANT\n",
    "\n",
    "Review: \"asdfghjklasdfghjkl!!!\"\n",
    "Result: SPAM\n",
    "\n",
    "Review: \"best game ever 10/10\"\n",
    "Result: RELEVANT\n",
    "\n",
    "Review: \"looooooooooooooooooooooooooooooooooooool\"\n",
    "Result: SPAM\n",
    "\n",
    "### CURRENT REVIEW TO CLASSIFY:\n",
    "Review: {input_text}\n",
    "Result:\"\"\"\n",
    "\n",
    "results = []\n",
    "for i, row in df_top_100.iterrows():\n",
    "\n",
    "    text = row[\"content\"]\n",
    "    reduced_text = text[:1000]\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt.format(input_text=reduced_text)}]\n",
    "\n",
    "    output = pipe(messages, max_new_tokens=2, temperature=0.1)\n",
    "    result = output[0][\"generated_text\"][-1][\"content\"].strip().upper()\n",
    "    if \"SPAM\" in result:\n",
    "        result = \"SPAM\"\n",
    "    else:\n",
    "        result = \"RELEVANT\"\n",
    "\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b9e8a82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'SPAM': 1, 'RELEVANT': 99})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "counts = defaultdict(int)\n",
    "for res in results:\n",
    "    counts[res] += 1\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2224152",
   "metadata": {},
   "source": [
    "Vemos que solo hay una marcada como SPAM. Las eliminamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "66dd3efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 99 entries, 1 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype\n",
      "---  ------         --------------  -----\n",
      " 0   content        99 non-null     str  \n",
      " 1   is_recomended  99 non-null     int64\n",
      " 2   cat            99 non-null     str  \n",
      "dtypes: int64(1), str(2)\n",
      "memory usage: 2.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_top_100[\"cat\"] = results\n",
    "df_top_100 = df_top_100[df_top_100[\"cat\"] != \"SPAM\"]\n",
    "\n",
    "df_top_100.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32a9d75",
   "metadata": {},
   "source": [
    "## Paso 3: extracción de datos\n",
    "\n",
    "El objetivo ahora es extraer información extructurada a partir de cada opinión. Tomaremos como referencia el formato impuesto en el enunciado.\n",
    "\n",
    "Usamos el mismo modelo de generación de texto pero con Instructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26ec6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Output(BaseModel):\n",
    "    sentiment: str = Field(description=\"Sentiment extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "dca5ec7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 338/338 [00:04<00:00, 82.11it/s, Materializing param=model.norm.weight]                               \n",
      "Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "pipe2 = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "933fea3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=200) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=200) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=200) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=200) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=200) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=200) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=200) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=200) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=200) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"<|im_start|>system\n",
    "You are a specialized game analyst. Extract information from game reviews into a strict JSON format.\n",
    "JSON fields:\n",
    "- sentiment: sentiment extracted from the user review. Possible values: positive, negative.\n",
    "- difficulty: difficulty of the game extracted from review. Possible values: easy, difficult, null (in case it is not defined).\n",
    "- positive_tags: tags with positive aspects extracted from user review about game(no repeat values).\n",
    "- negative_tags: tags with negative aspects extracted from user review about game(no repeat values).\n",
    "Only return the JSON object, nothing else.<|im_end|>\n",
    "<|im_start|>user\n",
    "Review: \"{input_text}\"\n",
    "\n",
    "JSON Schema:\n",
    "{{\n",
    "  \"sentiment\": \"string\",\n",
    "  \"positive_tags\": [\"string\"],\n",
    "  \"negative_tags\": [\"string\"],\n",
    "  \"difficulty\": \"string\"\n",
    "}}\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{{\"\"\"\n",
    "  \n",
    "results_2 = []\n",
    "for i, row in df_top_100.iterrows():\n",
    "    \n",
    "    if i == 10:\n",
    "        break\n",
    "\n",
    "    text = row[\"content\"]\n",
    "    reduced_text = text[:800]\n",
    "    _prompt = prompt.format(input_text=reduced_text)\n",
    "    output = pipe2(_prompt, max_new_tokens=200, temperature=0.7, return_full_text=False)\n",
    "    result = \"{\" + output[0][\"generated_text\"]\n",
    "    results_2.append(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2586a2c1",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8d935a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW: this was probably my first preorder i felt that if ...\n",
      "EXTRACTED: {'sentiment': 'positive', 'positive_tags': ['loving urban spaces', 'finding alleyways', 'seeing lit-up windows', 'many details and slices of life', 'full enjoyment', 'highest praise'], 'negative_tags': [], 'difficulty': 'null'}\n",
      "REVIEW: oh well admittedly its difficult for to write this ...\n",
      "EXTRACTED: {'sentiment': 'negative', 'positive_tags': [], 'negative_tags': ['dissapointing', 'biased', 'painful', 'huge fantasy and rpg fan', 'witcher franchise', 'favorite gaming franchises', 'entertaining quality content rich titles', 'favorite developer studio', 'topped it'], 'difficulty': 'difficult'}\n",
      "REVIEW: oh well admittedly its difficult for to write this ...\n",
      "EXTRACTED: {'sentiment': 'negative', 'positive_tags': ['fantasy', 'rpg', 'witcher', 'gwent', 'enjoyment'], 'negative_tags': ['dissapointing', 'biased', 'painful', 'huge fantasy and rpg fan', 'cdpr', 'their previous products', 'attitude towards their comm'], 'difficulty': 'difficult'}\n",
      "REVIEW: i know many will handwave away any criticisms of t ...\n",
      "EXTRACTED: {'sentiment': 'negative', 'positive_tags': [], 'negative_tags': ['punitive', 'least satisfying', 'especially punishing', 'too much', 'delayed attacks', 'enhanced tracking', 'better ai'], 'difficulty': 'difficult'}\n",
      "REVIEW: i had enormous expectations having put thousand ho ...\n",
      "EXTRACTED: {'sentiment': 'positive', 'positive_tags': ['enlarged expectations', 'experienced enjoyable gameplay', 'characteristic features', 'consistent quality'], 'negative_tags': [], 'difficulty': 'null'}\n",
      "REVIEW: i finished the witcher 3 for the first time this y ...\n",
      "EXTRACTED: {'sentiment': 'neutral', 'positive_tags': ['interesting story', \"invested in the game's lore\", \"excited for CDPR's new project\", 'hyped for the Witcher 3', \"considering The Witcher 3 as one of the best games I've ever played\"], 'negative_tags': [], 'difficulty': 'null'}\n",
      "REVIEW: in any industry this will always happen as an exam ...\n",
      "EXTRACTED: {'sentiment': 'positive', 'positive_tags': ['success', 'best game', 'impressive ai', 'unique designs'], 'negative_tags': [], 'difficulty': 'null'}\n",
      "REVIEW: now my favorite fromsoft game tldr here phenomenal ...\n",
      "EXTRACTED: {'sentiment': 'positive', 'positive_tags': ['fantastic', 'beautiful', 'performance issues', 'dark and twisted story', 'stealth', 'sekiro', 'heavy attacks', 'torrent', 'steed', 'styles of fighting', 'exploring different styles', 'gameplay', 'rewarding'], 'negative_tags': [], 'difficulty': 'difficult'}\n",
      "REVIEW: now my favorite fromsoft game tldr here phenomenal ...\n",
      "EXTRACTED: {'sentiment': 'positive', 'positive_tags': ['phenomenal', 'rich combat', 'beautiful world', 'packed with secrets', 'dark and twisted story', 'never spoon fed', 'performance issues', 'drops frames', 'beefy computer', 'highlight of the combat', 'rewards heavy attacks', 'steeds offer another layer of combat mechanics', 'many styles of fighting to master'], 'negative_tags': [], 'difficulty': 'difficult'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "loaded_jsons = [json.loads(res) for res in results_2]\n",
    "\n",
    "results_df = df_top_100.copy(deep=True).reset_index()\n",
    "results_df = results_df[results_df.index < len(loaded_jsons)]\n",
    "\n",
    "\n",
    "for (i, row), js in zip(results_df.iterrows(), loaded_jsons):\n",
    "    print(\"REVIEW:\", row[\"content\"][:50], \"...\")\n",
    "    print(\"EXTRACTED:\", js)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a50c09",
   "metadata": {},
   "source": [
    "Guardamos en un CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "96264250",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(loaded_jsons)\n",
    "final_df[\"review\"] = results_df[\"content\"]\n",
    "final_df.to_csv(\"./results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26743cb4",
   "metadata": {},
   "source": [
    "## Notas\n",
    "\n",
    "- Había pensado en aplicar zero-shot-classification, pero no conweguía buenos resultados.\n",
    "- Utilizando Qwen 2.5, el modelo de 0.5B de parámetros se quedaba corto en ambas tareas.\n",
    "- En el prompt de la primera tarea he tenido que añadir unos ejemplos (few-shot) para conseguri buenos resultados.\n",
    "- En el prompt de la segunda tarea, he debido indicar que no ponga tags repetidos.\n",
    "- Sorry por los warnings :("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
